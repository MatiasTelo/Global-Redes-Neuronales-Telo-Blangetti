{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRLIwyyYK9xd"
      },
      "source": [
        "# Procesamiento de datos del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsolgERK-_Fg",
        "outputId": "fb748898-0a36-427b-83eb-03ee2ca024e8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Global-Redes-Neuronales-Telo-Blangetti'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 82 (delta 33), reused 69 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (82/82), 39.43 MiB | 11.13 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "Archivos copiados con éxito.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MatiasTelo/Global-Redes-Neuronales-Telo-Blangetti\n",
        "# Crear carpetas de destino\n",
        "\n",
        "print(\"Archivos copiados con éxito.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El procesamiento del dataset se realizo de la siguiente manera:\n",
        "\n",
        "\n",
        "\n",
        "*   Primero definimos el vocabulario y creamos un diccionario para pasar de caracter a numero y viceversa\n",
        "*   Luego obtenemos los txt descargados del dataset y los guardamos en una variable\n",
        "*   Guardamos el diccionario de char to index\n",
        "*   En prepare_segments lo que hacemos es dividir los txt primero en 14 filas para definir el alto del segmento y luego lo dividimos en 32 columnas para el ancho, nos aseguramos de llenar espacios si faltan y cada segmento se agrega al array de segments\n",
        "*   En get item lo que hacemos es a cada segmento agregarle una dimension adicional del tamaño del vocabulario para hacer un one-hot de cada caracter\n",
        "\n",
        "\n",
        "Adicionalmente agregamos una funcion para visualizar los segmentos que nos devuelve el dataset que nos sirve de utilidad para ver que todo se haya procesado bien y ademas para cuando generemos segmentos con la gan tambien podamos usar esta funcion para verlos\n",
        "\n"
      ],
      "metadata": {
        "id": "gJK2tV7BxfyO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UDLv0fiuCwli"
      },
      "outputs": [],
      "source": [
        "\n",
        "import glob\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "# Definir el vocabulario\n",
        "CHARACTER_SET = ['X', 'S', '-', '?', 'Q', 'E', '<', '>', '[', ']', 'o', 'B', 'b']\n",
        "char2idx = {char: idx for idx, char in enumerate(CHARACTER_SET)}\n",
        "idx2char = {idx: char for char, idx in char2idx.items()}\n",
        "VOCAB_SIZE = len(CHARACTER_SET)\n",
        "\n",
        "class MarioLevelDataset(Dataset):\n",
        "    def __init__(self, folder_path, level_height=14, segment_width=32, step=16, char2idx=None):\n",
        "        super().__init__()\n",
        "        self.level_files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
        "        self.level_height = level_height\n",
        "        self.segment_width = segment_width\n",
        "        self.step = step\n",
        "\n",
        "        # Mapa char->idx obligatorio\n",
        "        if char2idx is None:\n",
        "            raise ValueError(\"Debes pasar un diccionario char2idx\")\n",
        "        self.char2idx = char2idx\n",
        "\n",
        "        # Aquí guardamos todos los segmentos de todos los niveles\n",
        "        self.segments = []\n",
        "        self._prepare_segments()\n",
        "\n",
        "    def _prepare_segments(self):\n",
        "        for file_path in self.level_files:\n",
        "            with open(file_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            # Limpio líneas y fijo altura\n",
        "            lines = [line.rstrip('\\n')[:] for line in lines[:self.level_height]]\n",
        "            # Completo si faltan filas\n",
        "            while len(lines) < self.level_height:\n",
        "                lines.append('-' * len(lines[0]))\n",
        "\n",
        "            level_width = max(len(line) for line in lines)\n",
        "            # Completo cada línea a nivel_width (con '-')\n",
        "            lines = [line.ljust(level_width, '-') for line in lines]\n",
        "\n",
        "            # Segmentar horizontalmente con step\n",
        "            for start_col in range(0, level_width - self.segment_width + 1, self.step):\n",
        "                segment = [line[start_col:start_col+self.segment_width] for line in lines]\n",
        "                self.segments.append(segment)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.segments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      segment = self.segments[idx]\n",
        "      arr = [[self.char2idx.get(ch, 0) for ch in row] for row in segment]\n",
        "      tensor = torch.tensor(arr, dtype=torch.long)\n",
        "      one_hot = F.one_hot(tensor, num_classes=len(self.char2idx))  # (14, 32, vocab)\n",
        "      one_hot = one_hot.permute(2, 0, 1)  # -> (vocab, 14, 32)\n",
        "      return one_hot.float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TfZGdiJfxYY2"
      },
      "outputs": [],
      "source": [
        "# Rutas y parámetros\n",
        "data_path = 'Global-Redes-Neuronales-Telo-Blangetti/data/Processed'\n",
        "batch_size = 32\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Cargar dataset\n",
        "dataset = MarioLevelDataset(folder_path=data_path, char2idx=char2idx)\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEDTvciSK1h3"
      },
      "source": [
        "# Visualizacion de segmentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u9TO9iRGaoHg"
      },
      "outputs": [],
      "source": [
        "def visualizar_segmento(one_hot_tensor, idx2char):\n",
        "    \"\"\"\n",
        "    Convierte un tensor one-hot (VOCAB_SIZE, 14, 32) a texto y lo imprime.\n",
        "    \"\"\"\n",
        "    # (VOCAB_SIZE, 14, 32) → (14, 32) con los índices de mayor probabilidad\n",
        "    idx_tensor = one_hot_tensor.argmax(dim=0).cpu().numpy()\n",
        "\n",
        "    # Convertir cada índice a su carácter correspondiente\n",
        "    for row in idx_tensor:\n",
        "        line = ''.join(idx2char[i] for i in row)\n",
        "        print(line)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWtwmRRqa1HO",
        "outputId": "7bbe114d-30cb-4397-d2b9-6edb47b62005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "---------------E--XXX----XXX----\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "--oooo---------X----------------\n",
            "--oooo--------------------------\n",
            "--------XXX---------------------\n",
            "--------------------------------\n",
            "XXXXXXX-------------------------\n",
            "X-------------------------------\n",
            "X-------------------------------\n",
            "--------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Elegí un índice de segmento, por ejemplo el primero\n",
        "segmento = dataset[347]  # (VOCAB_SIZE, 14, 32)\n",
        "\n",
        "# Visualizarlo\n",
        "visualizar_segmento(segmento, idx2char)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaUApyh13Dn_"
      },
      "source": [
        "# Utilidad para visualizacion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cargar_sprites(path=\"Global-Redes-Neuronales-Telo-Blangetti/data/Sprites\"):\n",
        "    \"\"\"\n",
        "    Carga las imágenes PNG de tiles en un diccionario: {char: PIL.Image}\n",
        "    \"\"\"\n",
        "    sprites = {}\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith(\".png\"):\n",
        "            key = os.path.splitext(filename)[0]  # nombre sin extensión\n",
        "            if key == \"D\":\n",
        "                key = \"<\"\n",
        "            elif key == \"I\":\n",
        "                key = \">\"\n",
        "            elif key == \"P\":\n",
        "                key = \"B\"\n",
        "            elif key == \"A\":\n",
        "                key = \"?\"\n",
        "            sprites[key] = Image.open(os.path.join(path, filename)).convert(\"RGBA\")\n",
        "    return sprites\n"
      ],
      "metadata": {
        "id": "GTBRn4KewQdu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def tensor_a_imagen(one_hot_tensor, idx2char, sprites, tile_size=(16, 16)):\n",
        "    \"\"\"\n",
        "    Convierte un tensor one-hot (VOCAB_SIZE, 14, 32) en una imagen compuesta de sprites.\n",
        "    \"\"\"\n",
        "    idx_tensor = one_hot_tensor.argmax(dim=0).cpu().numpy()  # (14, 32)\n",
        "\n",
        "    rows, cols = idx_tensor.shape\n",
        "    tile_width, tile_height = tile_size\n",
        "\n",
        "    # Crear imagen en blanco del tamaño total\n",
        "    output = Image.new('RGBA', (cols * tile_width, rows * tile_height))\n",
        "\n",
        "    for y in range(rows):\n",
        "        for x in range(cols):\n",
        "            char = idx2char[idx_tensor[y][x]]\n",
        "            sprite = sprites.get(char, None)\n",
        "            if sprite:\n",
        "                output.paste(sprite, (x * tile_width, y * tile_height), mask=sprite)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "YfiPLPW-wWVD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sprites = cargar_sprites()\n",
        "# Verificar primero la forma\n",
        "print(f\"Forma de fake2: {segmento.shape}\")\n",
        "\n",
        "imagen_resultado = tensor_a_imagen(segmento, idx2char, sprites)\n",
        "display(imagen_resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "nTV7Nw-w-9Rq",
        "outputId": "ab472673-1f09-4175-b244-a96429382cba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de fake2: torch.Size([13, 14, 32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=512x224>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Procesamiento de datos.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}